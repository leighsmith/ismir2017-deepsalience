{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacky notebook for tesing different models\n",
    "\n",
    "Not used in final experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../deepsalience/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import librosa\n",
    "import mir_eval\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "import compute_training_data as C\n",
    "\n",
    "def test_path():\n",
    "    return '/scratch/rmb456/multif0_ismir2017/test_data/'\n",
    "\n",
    "\n",
    "def get_single_test_prediction(npy_file, model):\n",
    "    input_hcqt = np.load(npy_file).transpose(1, 2, 0)[np.newaxis, :, :, :]\n",
    "\n",
    "    n_t = input_hcqt.shape[2]\n",
    "    t_slices = list(np.arange(0, n_t, 5000))\n",
    "    output_list = []\n",
    "    for t in t_slices:\n",
    "        output_list.append(\n",
    "            model.predict(input_hcqt[:, :, t:t+5000, :])[0, :, :]\n",
    "        )\n",
    "\n",
    "    predicted_output = np.hstack(output_list)\n",
    "    return predicted_output, input_hcqt\n",
    "\n",
    "\n",
    "def pitch_activations_to_mf0(pitch_activation_mat, thresh):\n",
    "    freqs = C.get_freq_grid()\n",
    "    times = C.get_time_grid(pitch_activation_mat.shape[1])\n",
    "\n",
    "    idx = np.where(pitch_activation_mat >= thresh)\n",
    "\n",
    "    freqs = [[] for _ in range(len(times))]\n",
    "    for f, t in zip(idx[0], idx[1]):\n",
    "        freqs[t].append(freqs[f])\n",
    "\n",
    "    freqs = [np.array(lst) for lst in freqs]\n",
    "    return times, freqs\n",
    "\n",
    "\n",
    "def save_multif0_output(times, freqs, output_path):\n",
    "    with open(output_path, 'w') as fhandle:\n",
    "        csv_writer = csv.writer(fhandle, delimiter='\\t')\n",
    "        for t, f in zip(times, freqs):\n",
    "            csv_writer.writerow([t] + f)\n",
    "\n",
    "\n",
    "def score_on_test_set(test_set_name, model, save_path):\n",
    "\n",
    "    # get files for this test set\n",
    "    test_set_path = os.path.join(test_path(), test_set_name)\n",
    "    test_npy_files = glob.glob(os.path.join(test_set_path, '*.npy'))\n",
    "\n",
    "    all_scores = []\n",
    "    for npy_file in test_npy_files:\n",
    "        # get input npy file and ground truth label pair\n",
    "        file_keys = os.path.basename(npy_file).replace('-', '_').split('_')[:2]\n",
    "        label_file = glob.glob(\n",
    "            os.path.join(test_set_path, \"{}*{}*.txt\".format(file_keys[0], file_keys[1]))\n",
    "        )[0]\n",
    "        \n",
    "        # generate prediction on numpy file\n",
    "        predicted_output, _ = get_single_test_prediction(npy_file, model)\n",
    "        \n",
    "        # save prediction\n",
    "        np.save(\n",
    "            os.path.join(\n",
    "                save_path,\n",
    "                \"{}_{}_prediction.npy\".format(file_keys[0], file_keys[1])\n",
    "            ),\n",
    "            predicted_output.astype(np.float32)    \n",
    "        )\n",
    "        \n",
    "        # get multif0 output from prediction\n",
    "        est_times, est_freqs = pitch_activations_to_mf0(predicted_output, 0.5)\n",
    "        \n",
    "        # save multif0 output\n",
    "        save_multif0_output(\n",
    "            est_times, est_freqs,\n",
    "            os.path.join(\n",
    "                save_path,\n",
    "                \"{}_{}_prediction.txt\".format(file_keys[0], file_keys[1])\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # load ground truth labels\n",
    "        ref_times, ref_freqs = mir_eval.io.load_ragged_time_series(label_file)\n",
    "        \n",
    "        # get multif0 metrics and append\n",
    "        scores = mir_eval.multipitch.evaluate(ref_times, ref_freqs, est_times, est_freqs)\n",
    "        scores['track'] = pair_key\n",
    "        all_scores.append(scores)\n",
    "    \n",
    "    # save scores to data frame\n",
    "    scores_path = os.path.join(save_path, '{}_all_scores.csv'.format(test_set_name))\n",
    "    score_summary_path = os.path.join(\n",
    "        save_path, \"{}_score_summary.csv\".format(test_set_name)\n",
    "    )\n",
    "    df = pandas.DataFrame(all_scores)\n",
    "    df.to_csv(scores_path)\n",
    "    df.describe().to_csv(score_summary_path)\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Reshape, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None, None, 6)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "y1 = Conv2D(64, (5, 5), padding='same', activation='relu', name='bendy1')(inputs)\n",
    "y1a = BatchNormalization()(y1)\n",
    "y2 = Conv2D(128, (3, 3), padding='same', activation='relu', name='harmonics')(y1a)\n",
    "y2a = BatchNormalization()(y2)\n",
    "y3 = Conv2D(256, (3, 3), padding='same', activation='relu', name='smoothy1')(y2a)\n",
    "y3a = BatchNormalization()(y3)\n",
    "y4 = Conv2D(1, (1, 1), padding='same', activation='sigmoid', name='squishy')(y3a)\n",
    "predictions = Lambda(lambda x: K.squeeze(x, axis=3))(y4)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.train(model, '../experiment_output/notebook_test6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"../experiment_output/multif0_exper7_3/multif0_exper7_3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot filters\n",
    "conv_layer = model.get_layer(name='distribution')\n",
    "weights = conv_layer.get_weights()\n",
    "weight_array = weights[0]\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i in range(8):\n",
    "    plt.subplot(1, 8, i+1)\n",
    "#     plt.plot(weight_array[:, :, 0, i])\n",
    "    plt.imshow(weight_array[:, :, 0, i], origin='lower', vmin=weight_array.min(), vmax=weight_array.max())\n",
    "    plt.axis('auto')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot filters\n",
    "conv_layer = model.get_layer(name='bendy1')\n",
    "weights = conv_layer.get_weights()\n",
    "weight_array = weights[0]\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(64):\n",
    "    plt.subplot(8, 8, i+1)\n",
    "    plt.imshow(weight_array[:, :, 1, i], origin='lower', vmin=weight_array.min(), vmax=weight_array.max())\n",
    "    plt.axis('square')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot filters\n",
    "conv_layer = model.get_layer(name='deharm')\n",
    "weights = conv_layer.get_weights()\n",
    "weight_array = weights[0]\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(16):\n",
    "    plt.subplot(2, 8, i+1)\n",
    "    plt.imshow(weight_array[:, :, 0, i], origin='lower', vmin=weight_array.min(), vmax=weight_array.max())\n",
    "    plt.axis('auto')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
