{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook wasn't used\n",
    "\n",
    "Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mir_eval\n",
    "import medleydb\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import mir_eval.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piano_score(trackid, best_thresh=0.3):\n",
    "\n",
    "    mtrack = medleydb.MultiTrack(trackid)\n",
    "    pred_path = \"../model_11b_mel2_outputs/{}_prediction.npy\".format(trackid)\n",
    "    df_ref = pd.DataFrame.from_records(mtrack.melody2_annotation, columns=['time', 'frequency'])\n",
    "\n",
    "    piano_stem = list({k: mtrack.stems[k].instrument for k in mtrack.stems if 'piano' in mtrack.stems[k].instrument[0]}.keys())\n",
    "    if len(piano_stem) > 0:\n",
    "        piano_stem = piano_stem[0]\n",
    "        if 'melody' == mtrack.stems[piano_stem].component:\n",
    "            dfp = pd.DataFrame.from_records(\n",
    "                mtrack.activation_conf_from_stem(piano_stem),\n",
    "                columns=['time', 'activation']\n",
    "            )\n",
    "\n",
    "            piano_activation, piano_voicing = mir_eval.melody.resample_melody_series(dfp['time'],\n",
    "                                                   dfp['activation'],\n",
    "                                                   dfp['activation']>0.5,\n",
    "                                                   df_ref['time'])\n",
    "        else:\n",
    "            piano_stem = None\n",
    "    else:\n",
    "        piano_stem = None\n",
    "        \n",
    "\n",
    "    est_times, est_freqs = get_mel_prediction(pred_path, best_thresh)\n",
    "    est_freq, est_voicing = mir_eval.melody.resample_melody_series(est_times, est_freqs,\n",
    "                                                                   est_freqs>0,\n",
    "                                                                   df_ref['time'])\n",
    "    df_est_res = pd.DataFrame()\n",
    "    df_est_res['time'] = df_ref['time']\n",
    "    df_est_res['frequency'] = est_freq\n",
    "\n",
    "    if piano_stem is not None:\n",
    "        print(piano_stem)\n",
    "        with_piano = mir_eval.melody.evaluate(df_ref['time'].loc[piano_voicing].values,\n",
    "                                              df_ref['frequency'].loc[piano_voicing].values,\n",
    "                                              df_est_res['time'].loc[piano_voicing].values,\n",
    "                                              df_est_res['frequency'].loc[piano_voicing].values)\n",
    "\n",
    "        without_piano = mir_eval.melody.evaluate(df_ref['time'].loc[~piano_voicing].values,\n",
    "                                                 df_ref['frequency'].loc[~piano_voicing].values,\n",
    "                                                 df_est_res['time'].loc[~piano_voicing].values,\n",
    "                                                 df_est_res['frequency'].loc[~piano_voicing].values)\n",
    "\n",
    "        return pd.DataFrame.from_records({'piano': with_piano, 'no_piano': without_piano})\n",
    "    else:\n",
    "        without_piano = mir_eval.melody.evaluate(df_ref['time'].values,\n",
    "                                                 df_ref['frequency'].values,\n",
    "                                                 df_est_res['time'].values,\n",
    "                                                 df_est_res['frequency'].values)\n",
    "        return pd.DataFrame.from_records({'piano': None, 'no_piano': without_piano})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../deepsalience/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compute_training_data as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mel_prediction(pred_path, thresh):\n",
    "    Y = np.load(pred_path)\n",
    "    Y = Y/np.max(np.max(Y))\n",
    "    max_idx = np.argmax(Y, axis=0)\n",
    "    est_times = C.get_time_grid(Y.shape[1])\n",
    "    freq_grid = C.get_freq_grid()\n",
    "    est_freqs = []\n",
    "    for i, f in enumerate(max_idx):\n",
    "        if Y[f, i] < thresh:\n",
    "            est_freqs.append(-1.0*freq_grid[f])\n",
    "        else:\n",
    "            est_freqs.append(freq_grid[f])\n",
    "    est_freqs = np.array(est_freqs)\n",
    "    return est_times, est_freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data_splits.json\", 'r') as fhandle:\n",
    "    dat_dict = json.load(fhandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_scores = []\n",
    "thresh = 0.3\n",
    "for trackid in dat_dict['test']:\n",
    "\n",
    "    print(trackid)\n",
    "    mtrack = medleydb.MultiTrack(trackid)\n",
    "    if mtrack.melody2_annotation is None:\n",
    "        continue\n",
    "\n",
    "    predominant_instrument = mtrack.predominant_stem.instrument[0]\n",
    "    print(\"    > {}\".format(predominant_instrument))\n",
    "    pred_path = \"../model_11b_mel2_outputs/{}_prediction.npy\".format(trackid)\n",
    "    est_times, est_freqs = get_mel_prediction(pred_path, thresh)\n",
    "    \n",
    "    mel2 = mtrack.melody2_annotation\n",
    "    mel2 = np.array(mel2).T\n",
    "    ref_times, ref_freqs = (mel2[0], mel2[1])\n",
    "    \n",
    "    scores = mir_eval.melody.evaluate(ref_times, ref_freqs, est_times, est_freqs)\n",
    "    scores['instrument'] = predominant_instrument\n",
    "    mel_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melinst = pd.DataFrame(mel_scores)\n",
    "inst_vals = set(df_melinst['instrument'].values)\n",
    "oa_vals = []\n",
    "rpa_vals = []\n",
    "for inst in inst_vals:\n",
    "    inst_df = df_melinst[df_melinst['instrument'] == inst]\n",
    "    oa_vals.append([inst_df['Overall Accuracy'].values])\n",
    "    rpa_vals.append([inst_df['Raw Pitch Accuracy'].values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, vals in enumerate(oa_vals):\n",
    "    for v in vals[0]:\n",
    "        plt.plot(i, v, 'or')\n",
    "\n",
    "plt.xticks(range(len(inst_vals)), inst_vals, rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
