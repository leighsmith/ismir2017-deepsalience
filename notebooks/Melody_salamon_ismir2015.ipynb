{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score the output of Melodia contours + ismir 2015 contour classifier on the full mixes in the medleydb test set against the melody2 annotations\n",
    "\n",
    "**This was not used in the end**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import motif\n",
    "import motif.plot\n",
    "import numpy as np\n",
    "import mir_eval\n",
    "import os\n",
    "import medleydb as mdb\n",
    "import seaborn\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Train/Test/Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../outputs/data_splits.json\", 'r') as fhandle:\n",
    "    dat_dict = json.load(fhandle)\n",
    "\n",
    "def get_file_pairs(track_id_list):\n",
    "    file_pairs = []\n",
    "    for track_id in track_id_list:\n",
    "        mtrack = mdb.MultiTrack(track_id)\n",
    "        if mtrack.dataset_version != 'V1':\n",
    "            continue\n",
    "        npy_path = \"../comparisons/multif0/experiment11b_output/fullmix_outputs/{}_prediction.npy\".format(track_id)\n",
    "        if os.path.exists(npy_path):\n",
    "            file_pairs.append([mtrack.mix_path, mtrack.melody2_fpath, track_id])\n",
    "    return file_pairs\n",
    "\n",
    "file_pairs_train = get_file_pairs(dat_dict['train'])\n",
    "file_pairs_validate = get_file_pairs(dat_dict['validate'])\n",
    "file_pairs_test = get_file_pairs(dat_dict['test'])\n",
    "\n",
    "ftr_bitt = motif.feature_extractors.BitteliFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get train/test/validate contours, features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_XY_pairs(etr, ftr, file_pairs):\n",
    "    contour_list = {}\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for mix_path, annotation, track_id in file_pairs:\n",
    "        print(track_id)\n",
    "        ctr = etr.compute_contours(mix_path)\n",
    "        Y_train, _ = ctr.compute_labels(annotation)\n",
    "        X_train = ftr.compute_all(ctr)\n",
    "\n",
    "        features_list.append(X_train)\n",
    "        labels_list.append(Y_train)\n",
    "        contour_list[track_id] = ctr\n",
    "\n",
    "    X = np.concatenate(features_list)\n",
    "    Y = np.concatenate(labels_list)\n",
    "    return X, Y, contour_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etr_sal = motif.contour_extractors.Salamon()\n",
    "\n",
    "X_train_sal, Y_train_sal, train_contours_sal = \\\n",
    "    get_XY_pairs(etr_sal, ftr_bitt, file_pairs_train)\n",
    "X_vaidate_sal, Y_validate_sal, validate_contours_sal = \\\n",
    "    get_XY_pairs(etr_sal, ftr_bitt, file_pairs_validate)\n",
    "X_test_sal, Y_test_sal, test_contours_sal = \\\n",
    "    get_XY_pairs(etr_sal, ftr_bitt, file_pairs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vaidate_sal, Y_validate_sal, validate_contours_sal = \\\n",
    "    get_XY_pairs(etr_sal, ftr_bitt, file_pairs_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train contour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_sal = motif.contour_classifiers.RandomForest()\n",
    "clf_sal.fit(X_train_sal, Y_train_sal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_classifier(clf, X, Y_true):\n",
    "    Y_prob = clf.predict(X)\n",
    "    Y_pred = (np.array(Y_prob >= clf.threshold)).astype(int)\n",
    "    scores = clf.score(Y_pred, Y_true, y_prob=Y_prob)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = score_classifier(clf_sal, X_train_sal, Y_train_sal)\n",
    "validate_scores = score_classifier(clf_sal, X_vaidate_sal, Y_validate_sal)\n",
    "test_scores = score_classifier(clf_sal, X_test_sal, Y_test_sal)\n",
    "\n",
    "print(train_scores)\n",
    "print(validate_scores)\n",
    "print(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get contour melody probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_melprobs(ftr, clf, contours_dict):\n",
    "    scores = {}\n",
    "\n",
    "    for trackid, ctr in contours_dict.items():\n",
    "        print(trackid)\n",
    "        X = ftr.compute_all(ctr)\n",
    "        Y = clf.predict(X)\n",
    "        scores[trackid] = Y\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_melprobs = get_contour_melprobs(\n",
    "    ftr_bitt, clf_sal, validate_contours_sal\n",
    ")\n",
    "test_melprobs = get_contour_melprobs(\n",
    "    ftr_bitt, clf_sal, test_contours_sal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best probability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(motif)\n",
    "reload(motif.contour_decoders)\n",
    "reload(motif.contour_decoders.maximum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcd = motif.contour_decoders.MaxDecoder()\n",
    "dcd.dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_vals = np.arange(0, 0.4, 0.01)\n",
    "mel_accuracy = {v: [] for v in thresh_vals}\n",
    "\n",
    "for trackid in validate_contours_sal.keys():\n",
    "    print(trackid)\n",
    "    mtrack = mdb.MultiTrack(trackid)\n",
    "\n",
    "    ctr = validate_contours_sal[trackid]\n",
    "    scores = validation_melprobs[trackid]    \n",
    "    \n",
    "    mel2 = mtrack.melody2_annotation\n",
    "    mel2 = np.array(mel2).T\n",
    "    ref_times, ref_freqs = (mel2[0], mel2[1])\n",
    "\n",
    "    for thresh in thresh_vals:\n",
    "        dcd = motif.contour_decoders.MaxDecoder(thresh=thresh)\n",
    "        est_times, est_freqs = dcd.decode(ctr, scores)\n",
    "\n",
    "        mel_scores = mir_eval.melody.evaluate(ref_times, ref_freqs, est_times, est_freqs)\n",
    "        mel_accuracy[thresh].append(mel_scores['Overall Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_vals = [np.mean(mel_accuracy[thresh]) for thresh in thresh_vals]\n",
    "best_thresh_idx = np.argmax(accuracy_vals)\n",
    "best_thresh = thresh_vals[best_thresh_idx]\n",
    "\n",
    "print(\"Best threshold is {} with an OA of {}\".format(\n",
    "    best_thresh, accuracy_vals[best_thresh_idx])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score Melody Outputs on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcd = motif.contour_decoders.MaxDecoder(thresh=best_thresh)\n",
    "\n",
    "all_mel_scores = []\n",
    "for trackid in test_contours_sal.keys():\n",
    "    print(trackid)\n",
    "    if trackid == 'MusicDelta_Gospel':\n",
    "        continue\n",
    "    mtrack = mdb.MultiTrack(trackid)\n",
    "    \n",
    "    ctr = test_contours_sal[trackid]\n",
    "    scores = test_melprobs[trackid]\n",
    "\n",
    "    mel2 = mtrack.melody2_annotation\n",
    "    mel2 = np.array(mel2).T\n",
    "    ref_times, ref_freqs = (mel2[0], mel2[1])\n",
    "    est_times, est_freqs = dcd.decode(ctr, scores)\n",
    "\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.title(trackid)\n",
    "    plt.plot(ref_times, ref_freqs, '.k', markersize=8)\n",
    "    plt.plot(est_times, est_freqs, '.r', markersize=3)\n",
    "    plt.show()\n",
    "\n",
    "    mel_scores = mir_eval.melody.evaluate(ref_times, ref_freqs, est_times, est_freqs)\n",
    "    all_mel_scores.append(mel_scores)\n",
    "\n",
    "mel_scores_df = pd.DataFrame(all_mel_scores)\n",
    "mel_scores_df.to_csv(\"Salamon_contourclf_mel2_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_scores_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
