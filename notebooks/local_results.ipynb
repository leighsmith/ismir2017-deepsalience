{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Reshape, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiment\n",
    "import core\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/Users/rabitt/Desktop/multif0_models/'\n",
    "model_name = 'multif0_exper10_batchin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "import librosa\n",
    "import mir_eval\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas\n",
    "import scipy\n",
    "\n",
    "import compute_training_data as C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None, None, 6)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "y0 = BatchNormalization()(inputs)\n",
    "y1 = Conv2D(256, (5, 5), padding='same', activation='relu', name='bendy1')(y0)\n",
    "y1a = BatchNormalization()(y1)\n",
    "y2 = Conv2D(16, (70, 3), padding='same', activation='relu', name='harmonics')(y1a)\n",
    "y2a = BatchNormalization()(y2)\n",
    "y3 = Conv2D(128, (3, 3), padding='same', activation='relu', name='smoothy1')(y2a)\n",
    "y3a = BatchNormalization()(y3)\n",
    "y4 = Conv2D(8, (360, 1), padding='same', activation='relu', name='distribution')(y3a)\n",
    "y4a = BatchNormalization()(y4)\n",
    "y5 = Conv2D(1, (1, 1), padding='same', activation='sigmoid', name='squishy')(y4a)\n",
    "predictions = Lambda(lambda x: K.squeeze(x, axis=3))(y5)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(model_path, \"{}.pkl\".format(model_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_on_test_set(model, thresh=0.3, save_path='/Users/rabitt/Desktop/'):\n",
    "    \"\"\"score a model on all files in a named test set\n",
    "    \"\"\"\n",
    "\n",
    "    # get files for this test set\n",
    "    test_set_path = os.path.join(\"../comparisons/mdb_test/\")\n",
    "    test_npy_files = glob.glob(os.path.join(test_set_path, '*.npy'))\n",
    "\n",
    "    all_scores = []\n",
    "    for npy_file in sorted(test_npy_files):\n",
    "        # get input npy file and ground truth label pair\n",
    "        file_keys = os.path.basename(npy_file).replace('-', '_').split('_')[:2]\n",
    "        label_file = glob.glob(\n",
    "            os.path.join(\n",
    "                test_set_path,\n",
    "                \"{}*{}*.txt\".format(file_keys[0], file_keys[1]))\n",
    "        )[0]\n",
    "\n",
    "        # generate prediction on numpy file\n",
    "        predicted_output, input_hcqt = \\\n",
    "            evaluate.get_single_test_prediction(npy_file, model)\n",
    "\n",
    "        # save plot for first example\n",
    "        if len(all_scores) == 0:\n",
    "            plot_save_path = os.path.join(\n",
    "                save_path,\n",
    "                \"{}_{}_plot_output.pdf\".format(file_keys[0], file_keys[1])\n",
    "            )\n",
    "\n",
    "            plt.figure(figsize=(15, 15))\n",
    "\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.imshow(input_hcqt[0, :, :, 1], origin='lower')\n",
    "            plt.axis('auto')\n",
    "            plt.colorbar()\n",
    "\n",
    "            plt.subplot(2, 1, 2)\n",
    "            plt.imshow(predicted_output, origin='lower')\n",
    "            plt.axis('auto')\n",
    "            plt.colorbar()\n",
    "\n",
    "            plt.savefig(plot_save_path, format='pdf')\n",
    "            plt.close()\n",
    "\n",
    "        # save prediction\n",
    "        np.save(\n",
    "            os.path.join(\n",
    "                save_path,\n",
    "                \"{}_{}_prediction.npy\".format(file_keys[0], file_keys[1])\n",
    "            ),\n",
    "            predicted_output.astype(np.float32)\n",
    "        )\n",
    "\n",
    "        # get multif0 output from prediction\n",
    "        est_times, est_freqs = evaluate.pitch_activations_to_mf0(predicted_output, thresh)\n",
    "\n",
    "        # save multif0 output\n",
    "        evaluate.save_multif0_output(\n",
    "            est_times, est_freqs,\n",
    "            os.path.join(\n",
    "                save_path,\n",
    "                \"{}_{}_prediction.txt\".format(file_keys[0], file_keys[1])\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # load ground truth labels\n",
    "        ref_times, ref_freqs = \\\n",
    "            mir_eval.io.load_ragged_time_series(label_file)\n",
    "\n",
    "        # get multif0 metrics and append\n",
    "        scores = mir_eval.multipitch.evaluate(\n",
    "            ref_times, ref_freqs, est_times, est_freqs)\n",
    "        scores['track'] = '_'.join(file_keys)\n",
    "        all_scores.append(scores)\n",
    "\n",
    "    # save scores to data frame\n",
    "    scores_path = os.path.join(\n",
    "        save_path, '{}_all_scores.csv'.format(test_set_name)\n",
    "    )\n",
    "    score_summary_path = os.path.join(\n",
    "        save_path, \"{}_score_summary.csv\".format(test_set_name)\n",
    "    )\n",
    "    df = pandas.DataFrame(all_scores)\n",
    "    df.to_csv(scores_path)\n",
    "    df.describe().to_csv(score_summary_path)\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_on_test_set(model, thresh=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
