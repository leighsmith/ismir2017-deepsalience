{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bach10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dfbox(dataset, metrics):\n",
    "    df_benetos = pd.DataFrame.from_csv(\"algorithm_outputs/{}_benetos_all_scores.csv\".format(dataset))\n",
    "    df_duan = pd.DataFrame.from_csv(\"algorithm_outputs/{}_duan_all_scores.csv\".format(dataset))\n",
    "    df_bittner = pd.DataFrame.from_csv(\"../experiment11b_output/{}_all_scores.csv\".format(dataset))\n",
    "    \n",
    "    boxdata = []\n",
    "    for metric in metrics:\n",
    "        boxdata.extend([\n",
    "            df_benetos[metric],\n",
    "            df_duan[metric],\n",
    "            df_bittner[metric]\n",
    "        ])\n",
    "\n",
    "    dfbox = pd.DataFrame(np.array(boxdata).T)\n",
    "    return dfbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_plot(subplot_tuple, metrics, dfbox, title, show_yaxis=True, legend_loc=None, xlim=None):\n",
    "    plt.subplot(subplot_tuple)\n",
    "    plt.title(title, weight='bold')\n",
    "    n_algs = 3\n",
    "    n_metrics = len(metrics)\n",
    "    positions = []\n",
    "    k = 1\n",
    "    for i in range(n_metrics):\n",
    "        for j in range(n_algs):\n",
    "            positions.append(k)\n",
    "            k = k + 1\n",
    "        k = k + 1\n",
    "\n",
    "#     current_palette = sns.color_palette('coolwarm', 3)\n",
    "#     current_palette = sns.diverging_palette(1, 220, sep=80, n=3)\n",
    "    current_palette = [\"#E1D89F\", \"#8EA8BD\", \"#CF6766\"]\n",
    "    colors = current_palette*n_metrics\n",
    "\n",
    "    box = plt.boxplot(\n",
    "        dfbox.values, widths=0.8, positions=positions,\n",
    "        patch_artist=True, showmeans=True,\n",
    "        medianprops={'color': 'k'},\n",
    "        meanprops=dict(marker='D', markeredgecolor='black',\n",
    "            markerfacecolor='k'),\n",
    "        vert=False\n",
    "    )\n",
    "    for patch, color in zip(box['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "    plt.xlabel('Score')\n",
    "    if show_yaxis:\n",
    "        plt.yticks(np.arange(2, 4*(n_metrics + 1) - 2, 4), metrics, rotation='horizontal', weight='bold')\n",
    "    else:\n",
    "        plt.yticks(np.arange(2, 4*(n_metrics + 1) - 2, 4), ['']*len(metrics), rotation='horizontal')\n",
    "\n",
    "    if xlim is not None:\n",
    "        plt.xlim(xlim)\n",
    "        \n",
    "    if legend_loc is not None:\n",
    "        # draw temporary red and blue lines and use them to create a legend\n",
    "        h_benetos, = plt.plot([1,1],'s',color=colors[0], markersize=10)\n",
    "        h_duan, = plt.plot([1,1],'s',color=colors[1], markersize=10)\n",
    "        h_cnn, = plt.plot([1,1],'s',color=colors[2], markersize=10)\n",
    "        lgd = plt.legend((h_cnn, h_duan, h_benetos),('CNN', 'Duan', 'Benetos'), ncol=1, loc=legend_loc)\n",
    "\n",
    "        h_benetos.set_visible(False)\n",
    "        h_duan.set_visible(False)\n",
    "        h_cnn.set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4))\n",
    "sns.set(font_scale=1.2)\n",
    "sns.set_style('whitegrid')\n",
    "metrics = ['Recall', 'Precision', 'Chroma Accuracy', 'Accuracy']\n",
    "df_bach10 = get_dfbox('bach10', metrics)\n",
    "df_su = get_dfbox('su', metrics)\n",
    "df_mdb = get_dfbox('mdb_test', metrics)\n",
    "\n",
    "add_plot(131, metrics, df_bach10, 'Bach10', xlim=[0.1, 1.0])\n",
    "add_plot(132, metrics, df_su, 'Su', show_yaxis=False, xlim=[0.1, 1.0], legend_loc=1)\n",
    "add_plot(133, metrics, df_mdb, 'MedleyDB', xlim=[0.1, 1.0], show_yaxis=False)\n",
    "\n",
    "# metrics = ['Miss Error', 'Substitution Error', 'False Alarm Error', 'Total Error']\n",
    "# df_bach10 = get_dfbox('bach10', metrics)\n",
    "# df_su = get_dfbox('su', metrics)\n",
    "# df_mdb = get_dfbox('mdb_test', metrics)\n",
    "\n",
    "# add_plot(234, metrics, df_bach10, 'Bach10', xlim=[0.0, 0.5])\n",
    "# add_plot(235, metrics, df_su, 'Su', show_yaxis=False, legend_loc=2, xlim=[0.0, 1.0])\n",
    "# add_plot(236, metrics, df_mdb, 'MedleyDB', show_yaxis=False, xlim=[0, 4])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Multif0_accuracy.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_track_diffs(dataset):\n",
    "    df_benetos = pd.DataFrame.from_csv(\"algorithm_outputs/{}_benetos_all_scores.csv\".format(dataset))\n",
    "    df_duan = pd.DataFrame.from_csv(\"algorithm_outputs/{}_duan_all_scores.csv\".format(dataset))\n",
    "    df_bittner = pd.DataFrame.from_csv(\"../experiment11b_output/{}_all_scores.csv\".format(dataset))\n",
    "\n",
    "    tracks = df_benetos['track']\n",
    "    bittner_accuracy = df_bittner['Accuracy']\n",
    "    benetos_accuracy = df_benetos['Accuracy']\n",
    "    duan_accuracy = df_duan['Accuracy']\n",
    "\n",
    "    mdb_track_diffs = []\n",
    "    for i, track in enumerate(tracks):\n",
    "        mdb_track_diffs.append(bittner_accuracy[i] - np.max([benetos_accuracy[i], duan_accuracy[i]]))\n",
    "\n",
    "    return tracks, mdb_track_diffs, [dataset]*len(tracks)\n",
    "\n",
    "tracks_mdb, diffs_mdb, color_mdb = get_track_diffs('mdb_test')\n",
    "tracks_bach10, diffs_bach10, color_bach10 = get_track_diffs('bach10')\n",
    "tracks_su, diffs_su, color_su = get_track_diffs('su')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_tracks = np.concatenate([tracks_mdb, tracks_bach10, tracks_su])\n",
    "# all_diffs = np.concatenate([diffs_mdb, diffs_bach10, diffs_su])\n",
    "# all_colors = np.concatenate([color_mdb, color_bach10, color_su])\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "k = 1\n",
    "for tracks, diffs, title in zip(\n",
    "    [tracks_bach10, tracks_su, tracks_mdb],\n",
    "    [diffs_bach10, diffs_su, diffs_mdb],\n",
    "    ['Bach10', 'Su', 'MedleyDB']):\n",
    "    if k < 3:\n",
    "        plt.subplot(1, 4, k)\n",
    "    else:\n",
    "        plt.subplot(1, 2, 2)\n",
    "    sort_idx = np.flip(np.argsort(diffs), 0)\n",
    "    \n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.set_style('whitegrid')\n",
    "\n",
    "    for i, j in enumerate(sort_idx):\n",
    "        plt.bar(i, diffs[j], color='#CF6766')\n",
    "    \n",
    "    plt.title(title, weight='bold')\n",
    "    plt.xticks([])\n",
    "    \n",
    "    if k == 1:\n",
    "        plt.ylabel(\"Maximum accuracy difference\")\n",
    "    \n",
    "    k = k + 1\n",
    "\n",
    "    plt.ylim([-0.25, 0.35])\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0)\n",
    "plt.savefig(\"../paper-figs/multif0_trackdiffs.pdf\", format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = df_benetos['track']\n",
    "bittner_accuracy = df_bittner['Accuracy']\n",
    "benetos_accuracy = df_benetos['Accuracy']\n",
    "duan_accuracy = df_duan['Accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "sns.set_style('white')\n",
    "plt.plot(bittner_accuracy, 'or')\n",
    "plt.plot(benetos_accuracy, 'ob')\n",
    "plt.plot(duan_accuracy, 'oy')\n",
    "plt.xticks(range(len(tracks)), tracks, rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = [\n",
    "    'AClassicEducation_NightOwl',\n",
    "    'Auctioneer_OurFutureFaces',\n",
    "    'CelestialShore_DieForUs',\n",
    "    'ChrisJacoby_BoothShotLincoln',\n",
    "    'ChrisJacoby_PigsFoot',\n",
    "    'Creepoid_OldTree',\n",
    "    'Debussy_LenfantProdigue',\n",
    "    'Grants_PunchDrunk',\n",
    "    'MatthewEntwistle_DontYouEver',\n",
    "    'MatthewEntwistle_FairerHopes',\n",
    "    'MatthewEntwistle_ImpressionsOfSaturn',\n",
    "    'MatthewEntwistle_Lontano',\n",
    "    'MatthewEntwistle_TheArch',\n",
    "    'MatthewEntwistle_TheFlaxenField',\n",
    "    'Mozart_DiesBildnis',\n",
    "    'MusicDelta_FusionJazz',\n",
    "    'MusicDelta_Gospel',\n",
    "    'MusicDelta_Pachelbel',\n",
    "    'MusicDelta_SwingJazz',\n",
    "    'Phoenix_BrokenPledgeChicagoReel',\n",
    "    'Phoenix_ColliersDaughter',\n",
    "    'Phoenix_ElzicsFarewell',\n",
    "    'Phoenix_LarkOnTheStrandDrummondCastle',\n",
    "    'Phoenix_ScotchMorris',\n",
    "    'Phoenix_SeanCaughlinsTheScartaglen',\n",
    "    'PortStWillow_StayEven',\n",
    "    'Schubert_Erstarrung',\n",
    "    'StrandOfOaks_Spacestation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mir_eval\n",
    "\n",
    "track_avg_poly = []\n",
    "track_max_poly = []\n",
    "for track in tracks:\n",
    "    ground_truth_path = '../comparisons/mdb_test/{}.txt'.format(track)\n",
    "    _, ref_freqs = mir_eval.io.load_ragged_time_series(ground_truth_path)\n",
    "    polyph = [len(f) for f in ref_freqs]\n",
    "    avg_polyphony = np.mean(polyph)\n",
    "    max_polyphony = np.max(polyph)\n",
    "    track_avg_poly.append(avg_polyphony)\n",
    "    track_max_poly.append(max_polyphony)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'Accuracy'\n",
    "bittner_accuracy = df_bittner[metric]\n",
    "benetos_accuracy = df_benetos[metric]\n",
    "duan_accuracy = df_duan[metric]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.set_style('white')\n",
    "\n",
    "plt.subplot(1,2, 1)\n",
    "for i, track in enumerate(tracks):\n",
    "\n",
    "    plt.plot(track_avg_poly[i], bittner_accuracy[i], 'o', color=\"#CF6766\")\n",
    "    plt.plot(track_avg_poly[i], benetos_accuracy[i], 'o', color=\"#E1D89F\")\n",
    "    plt.plot(track_avg_poly[i], duan_accuracy[i], 'o', color=\"#8EA8BD\")\n",
    "plt.xlabel('Average polyphony')\n",
    "plt.ylabel(metric)\n",
    "    \n",
    "plt.subplot(1,2, 2)\n",
    "for i, track in enumerate(tracks):\n",
    "\n",
    "    plt.plot(track_max_poly[i], bittner_accuracy[i], 'o', color=\"#CF6766\")\n",
    "    plt.plot(track_max_poly[i], benetos_accuracy[i], 'o', color=\"#E1D89F\")\n",
    "    plt.plot(track_max_poly[i], duan_accuracy[i], 'o', color=\"#8EA8BD\")\n",
    "\n",
    "plt.xlabel('Max polyphony')\n",
    "plt.ylabel(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
