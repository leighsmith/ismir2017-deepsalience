{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old and out of date -- do not use!\n",
    "\n",
    "Initial development notebook before everything was scriptified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Reshape, Lambda\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras import backend as K\n",
    "\n",
    "import medleydb as mdb\n",
    "import os\n",
    "import pandas\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pescador\n",
    "from medleydb import utils\n",
    "\n",
    "def keras_generator(data_list, input_patch_size,\n",
    "                    output_patch_size,\n",
    "                    with_replacement=True,\n",
    "                    batch_size=32):\n",
    "\n",
    "    streams = []\n",
    "    for fpath_in, fpath_out in data_list:\n",
    "        streams.append(\n",
    "            pescador.Streamer(\n",
    "                patch_generator, fpath_in, fpath_out,\n",
    "                input_patch_size=input_patch_size,\n",
    "                output_patch_size=output_patch_size,\n",
    "                batch_size=batch_size\n",
    "            )\n",
    "        )\n",
    "\n",
    "    stream_mux = pescador.Mux(\n",
    "        streams, 10, with_replacement=with_replacement, lam=500,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "\n",
    "#     buffered_streamer = pescador.BufferedStreamer(stream_mux, batch_size)\n",
    "\n",
    "    for batch in stream_mux.tuples('X', 'Y'):\n",
    "        yield batch\n",
    "\n",
    "\n",
    "def __grab_patch_output(f, t, n_f, n_t, y_data):\n",
    "    return y_data[f: f + n_f, t: t + n_t][np.newaxis, :, :]\n",
    "\n",
    "\n",
    "def __grab_patch_input(f, t, n_f, n_t, n_harms, x_data):\n",
    "    return np.transpose(\n",
    "        x_data[:, f: f + n_f, t: t + n_t], (1, 2, 0)\n",
    "    )[np.newaxis, :, :, :]\n",
    "\n",
    "\n",
    "def patch_generator(fpath_in, fpath_out, input_patch_size, output_patch_size, batch_size):\n",
    "    data_in = np.load(fpath_in)#, mmap_mode='r')\n",
    "    data_out = np.load(fpath_out)#, mmap_mode='r')\n",
    "    \n",
    "    n_harms, n_freqs, n_times = data_in.shape\n",
    "    n_f_in, n_t_in = input_patch_size\n",
    "    n_f_out, n_t_out = output_patch_size\n",
    "\n",
    "    f_shift = n_f_in - n_f_out\n",
    "    t_shift = n_t_in - n_t_out\n",
    "\n",
    "#     while True:\n",
    "    t_vals = np.arange(0, n_times - n_t_in)\n",
    "    np.random.shuffle(t_vals)\n",
    "    for t in t_vals:\n",
    "#         f = np.random.randint(0, n_freqs - n_f_in)\n",
    "        f = 0\n",
    "#         t = np.random.randint(0, n_times - n_t_in)\n",
    "\n",
    "        x = __grab_patch_input(\n",
    "            f, t, n_f_in, n_t_in, n_harms, data_in\n",
    "        )\n",
    "        y = __grab_patch_output(\n",
    "            f + f_shift, t + t_shift, n_f_out, n_t_out, data_out\n",
    "        )\n",
    "        yield dict(X=x, Y=y)\n",
    "\n",
    "\n",
    "def get_file_paths(mtrack_list, data_path):\n",
    "    file_paths = []\n",
    "    for track_id in mtrack_list:\n",
    "        input_path = glob.glob(\n",
    "            os.path.join(data_path, 'inputs', \"{}*_input.npy\".format(track_id))\n",
    "        )\n",
    "        output_path = glob.glob(\n",
    "            os.path.join(data_path, 'outputs', \"{}*_output.npy\".format(track_id))\n",
    "        )\n",
    "        \n",
    "        if len(input_path) == 1 and len(output_path) == 1:\n",
    "            input_path = input_path[0]\n",
    "            output_path = output_path[0]\n",
    "            file_paths.append((input_path, output_path))\n",
    "            \n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(object):\n",
    "\n",
    "    def __init__(self, mtrack_list, data_path, input_patch_size,\n",
    "                 output_patch_size, batch_size):\n",
    "\n",
    "        self.mtrack_list = mtrack_list\n",
    "        self.input_patch_size = input_patch_size\n",
    "        self.output_patch_size = output_patch_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.data_path = data_path\n",
    "        \n",
    "        (self.train_set,\n",
    "         self.validation_set,\n",
    "         self.test_set) = self._train_val_test_split()\n",
    "\n",
    "        self.train_files = get_file_paths(self.train_set, self.data_path)\n",
    "        self.validation_files = get_file_paths(\n",
    "            self.validation_set, self.data_path\n",
    "        )\n",
    "        self.test_files = get_file_paths(self.test_set, self.data_path)\n",
    "\n",
    "    def _train_val_test_split(self):\n",
    "        full_list = []\n",
    "        print(len(self.mtrack_list))\n",
    "        for m in self.mtrack_list:\n",
    "            globbed = get_file_paths([m], self.data_path)\n",
    "            if len(globbed) > 0:\n",
    "                full_list.append(m)\n",
    "\n",
    "        self.full_list = full_list\n",
    "        print(len(full_list))\n",
    "        mtracks = list(mdb.load_multitracks(full_list))\n",
    "        test_potentials = [\n",
    "            m.track_id for m in mtracks if m.dataset_version == 'V1'\n",
    "        ]\n",
    "        all_others = [\n",
    "            m.track_id for m in mtracks if m.dataset_version != 'V1'\n",
    "        ]\n",
    "\n",
    "        split1 = utils.artist_conditional_split(\n",
    "            trackid_list=test_potentials, test_size=0.2,\n",
    "            num_splits=1, random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        test_set = split1[0]['test']\n",
    "        remaining_tracks = split1[0]['train'] + all_others\n",
    "\n",
    "        split2 = utils.artist_conditional_split(\n",
    "            trackid_list=remaining_tracks, test_size=0.15,\n",
    "            num_splits=1, random_state=RANDOM_STATE\n",
    "        )\n",
    "\n",
    "        train_set = split2[0]['train']\n",
    "        validation_set = split2[0]['test']\n",
    "\n",
    "        return train_set, validation_set, test_set\n",
    "\n",
    "    def get_train_generator(self):\n",
    "        return keras_generator(\n",
    "            self.train_files,\n",
    "            input_patch_size=self.input_patch_size,\n",
    "            output_patch_size=self.output_patch_size,\n",
    "            batch_size=self.batch_size\n",
    "        )\n",
    "\n",
    "    def get_validation_generator(self):\n",
    "        return keras_generator(\n",
    "            self.validation_files,\n",
    "            input_patch_size=self.input_patch_size,\n",
    "            output_patch_size=self.output_patch_size,\n",
    "            batch_size=self.batch_size\n",
    "        )\n",
    "\n",
    "    def get_test_generator(self):\n",
    "        return keras_generator(\n",
    "            self.test_files,\n",
    "            input_patch_size=self.input_patch_size,\n",
    "            output_patch_size=self.output_patch_size,\n",
    "            batch_size=self.batch_size\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/scratch/rmb456/multif0_ismir2017/training_data_with_blur/multif0_complete/\"\n",
    "mtrack_list = mdb.TRACK_LIST_V1 + mdb.TRACK_LIST_V2 + mdb.TRACK_LIST_EXTRA #+ mdb.TRACK_LIST_BACH10\n",
    "dat = Data(\n",
    "    mtrack_list, data_path, input_patch_size=(360, 50),\n",
    "    output_patch_size=(360, 50), batch_size=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(dat.train_set))\n",
    "# print(len(dat.validation_set))\n",
    "print(dat.test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = dat.get_train_generator()\n",
    "validation_generator = dat.get_validation_generator()\n",
    "test_generator = dat.get_test_generator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "# LeakyReLU(alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (None, None, 6)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "y1 = Conv2D(\n",
    "    64, (5, 5), padding='same', activation='relu', name='bendy1'\n",
    ")(inputs)\n",
    "y2 = Conv2D(\n",
    "    64, (5, 5), padding='same', activation='relu', name='bendy2'\n",
    ")(y1)\n",
    "# y3 = Conv2D(\n",
    "#     8, (70, 3), padding='same', activation='relu', name='distribute', kernel_initializer='ones'\n",
    "# )(y2)\n",
    "y4 = Conv2D(\n",
    "    64, (3, 3), padding='same', activation='relu', name='smoothy1'\n",
    ")(y2)\n",
    "y5 = Conv2D(\n",
    "    64, (3, 3), padding='same', activation='relu', name='smoothy2'\n",
    ")(y4)\n",
    "y6 = Conv2D(\n",
    "    1, (1, 1), padding='same', activation='sigmoid', name='squishy'\n",
    ")(y5)\n",
    "predictions = Lambda(lambda x: K.squeeze(x, axis=3))(y6)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bkld(y_true, y_pred):\n",
    "    y_true = K.clip(y_true, K.epsilon(), 1.0 - K.epsilon())\n",
    "    y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
    "    return K.mean(K.mean(-1.0*y_true* K.log(y_pred) - (1.0 - y_true) * K.log(1.0 - y_pred), axis=-1), axis=-1)\n",
    "\n",
    "def soft_binary_accuracy(y_true, y_pred):\n",
    "    return K.mean(K.mean(K.equal(K.round(y_true), K.round(y_pred)),  \n",
    "        axis=-1), axis=-1)\n",
    "\n",
    "def smart_sum(x, axis=None, keepdims=False):\n",
    "    axis = K.tensorflow_backend._normalize_axis(axis, K.ndim(x))\n",
    "    if x.dtype.base_dtype == K.tf.bool:\n",
    "        x = K.tf.cast(x, K.floatx())\n",
    "    return K.tf.reduce_sum(x, reduction_indices=axis, keep_dims=keepdims)\n",
    "\n",
    "\n",
    "def mirex_acc_loss(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    n_est = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    n_ref = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    return true_positives / (n_est + n_ref - true_positives + K.epsilon())\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=0.5):\n",
    "    \"\"\"Computes the F score.\n",
    "\n",
    "    The F score is the weighted harmonic mean of precision and recall.\n",
    "    Here it is only computed as a batch-wise average, not globally.\n",
    "\n",
    "    This is useful for multi-label classification, where input samples can be\n",
    "    classified as sets of labels. By only using accuracy (precision) a model\n",
    "    would achieve a perfect score by simply assigning every class to every\n",
    "    input. In order to avoid this, a metric should penalize incorrect class\n",
    "    assignments as well (recall). The F-beta score (ranged from 0.0 to 1.0)\n",
    "    computes this, as a weighted mean of the proportion of correct class\n",
    "    assignments vs. the proportion of incorrect class assignments.\n",
    "\n",
    "    With beta = 1, this is equivalent to a F-measure. With beta < 1, assigning\n",
    "    correct classes becomes more important, and with beta > 1 the metric is\n",
    "    instead weighted towards penalizing incorrect class assignments.\n",
    "    \"\"\"\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "\n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss binary cross entropy\n",
    "model.compile(loss=bkld,\n",
    "              metrics=['mse', soft_binary_accuracy],#, fbeta_score, mirex_acc_loss],\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary(line_length=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/rmb456/repos/multif0/experiment_output/notebook_test4\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "samples_per_epoch = 512  # 512 batches, batches size 32\n",
    "nb_epochs = 100 # up to 100 epochs\n",
    "nb_val_samples = 512 # 1000\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator, samples_per_epoch, epochs=nb_epochs, verbose=1,\n",
    "    validation_data=validation_generator, validation_steps=nb_val_samples,\n",
    "    callbacks=[keras.callbacks.ModelCheckpoint(os.path.join(model_path, 'test_model.pkl'),\n",
    "                                           save_best_only=True, verbose=1),\n",
    "               keras.callbacks.ReduceLROnPlateau(patience=5, verbose=1),\n",
    "               keras.callbacks.EarlyStopping(patience=15, verbose=0)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../deepsalience/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import core as C\n",
    "reload(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(model_path, \"test_model.pkl\"))\n",
    "C.plot_metrics_epochs(history, os.path.join(model_path, \"multif0_exper1_loss.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.get_model_metrics(dat, model, os.path.join(model_path, \"multif0_exper1_model_scores.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C.get_all_multif0_metrics(\n",
    "    dat.test_files, model,\n",
    "    model_path,\n",
    "    os.path.join(model_path, \"multif0_exper1_scores.csv\"),\n",
    "    os.path.join(model_path, \"multif0_exper1_score_summary.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bach10_files = get_file_paths(mdb.TRACK_LIST_BACH10, dat.data_path)\n",
    "C.get_all_multif0_metrics(\n",
    "    bach10_files, model,\n",
    "    model_path,\n",
    "    os.path.join(model_path, \"bach10_scores.csv\"),\n",
    "    os.path.join(model_path, \"bach10_score_summary.csv\"), create_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(matplotlib)\n",
    "# plot filters\n",
    "conv_layer = model.get_layer(name='smoothy2')\n",
    "weights = conv_layer.get_weights()\n",
    "weight_array = weights[0]\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(64):\n",
    "    plt.subplot(8, 8, i+1)\n",
    "    plt.imshow(weight_array[:, :, 0, i], origin='lower')\n",
    "    plt.axis('square')\n",
    "\n",
    "plt.savefig('/home/rmb456/repos/multif0/filters4.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer = model.get_layer(name='distribute')\n",
    "weights = conv_layer.get_weights()\n",
    "weight_array = weights[0]\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(8):\n",
    "    plt.subplot(4, 2, i+1)\n",
    "    plt.imshow(weight_array[:, :, 0, i], origin='lower')\n",
    "    plt.axis('auto')\n",
    "\n",
    "plt.savefig('/home/rmb456/repos/multif0/filters2.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot filters\n",
    "conv_layer = model.get_layer(name='smoothy1')\n",
    "weights = conv_layer.get_weights()\n",
    "weight_array = weights[0]\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(64):\n",
    "    plt.subplot(8, 8, i+1)\n",
    "    plt.imshow(weight_array[:, :, 0, i], origin='lower')\n",
    "    plt.axis('square')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stuff(X, Y, Y_pred):\n",
    "    sns.set_style('white')\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    \n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.title(\"prediction\")\n",
    "    plt.imshow(Y_pred[0], origin='lower', cmap='hot', vmin=0, vmax=1)\n",
    "    plt.axis('auto')\n",
    "#     plt.xlim(a, b)\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.title('target')\n",
    "    plt.imshow(Y[0], origin='lower', cmap='hot', vmin=0, vmax=1)\n",
    "    plt.axis('auto')\n",
    "#     plt.xlim(a, b)\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.title('input')\n",
    "    plt.imshow(X[0, :, :, 0], origin='lower', cmap='hot', vmin=0, vmax=1)\n",
    "    plt.axis('auto')\n",
    "#     plt.xlim(a, b)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, Y in validation_generator:\n",
    "    Y_pred = model.predict(X)\n",
    "    plot_stuff(X, Y, Y_pred)\n",
    "    break\n",
    "    if np.sum(Y[0].flatten()) > 0:\n",
    "        plot_stuff(X, Y, Y_pred)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, Y in train_generator:\n",
    "    for x, y in zip(X, Y):\n",
    "        if np.sum(y.flatten()) > 0:\n",
    "            plt.figure(figsize=(15, 15))\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.imshow(x[:, :, 0], origin='lower', cmap='hot')\n",
    "            plt.axis('square')\n",
    "\n",
    "            plt.subplot(2, 1, 2)\n",
    "            plt.imshow(y, origin='lower', cmap='hot')\n",
    "            plt.axis('square')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_track_prediction(fpath_in, fpath_out, model):\n",
    "    \n",
    "    data_in = np.load(fpath_in, mmap_mode='r')\n",
    "    n_harms, n_freqs, n_times = data_in.shape\n",
    "    n_f, n_t = (20, 20)\n",
    "\n",
    "    prediction = np.zeros((n_freqs, n_times))\n",
    "\n",
    "    cqt_patch_generator = stride_tf(fpath_in, fpath_out, (26, 26), (20, 20))\n",
    "\n",
    "    for d in cqt_patch_generator:\n",
    "        f = d['f']\n",
    "        t = d['t']\n",
    "        print(\"{}, {}\".format(f, t))\n",
    "        y_pred = model.predict(d['X']).reshape(n_f, n_t)\n",
    "        prediction[f: f + n_f, t: t + n_t] = y_pred\n",
    "\n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_in, fpath_out = dat.test_files[0]\n",
    "test_prediction = get_full_track_prediction(fpath_in, fpath_out, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = (0, 25000)\n",
    "ground_truth = np.load(fpath_out, mmap_mode='r')\n",
    "input_data = np.load(fpath_in, mmap_mode='r')\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(1.0 - test_prediction[:, a:b], origin='lower', cmap='hot')\n",
    "# plt.imshow((1.0 - test_prediction)**1000, origin='lower', cmap='hot')\n",
    "plt.axis('auto')\n",
    "plt.xlim(a, b)\n",
    "# plt.colorbar()\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(ground_truth[:, a:b], origin='lower', cmap='hot')\n",
    "plt.axis('auto')\n",
    "plt.xlim(a, b)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(input_data[0, :, a:b], origin='lower', cmap='hot')\n",
    "plt.axis('auto')\n",
    "plt.xlim(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dat3['data_in'][0], origin='lower', cmap='hot')\n",
    "plt.axis('auto')\n",
    "plt.xlim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dat3['data_out'], origin='lower', cmap='hot')\n",
    "plt.axis('auto')\n",
    "plt.xlim(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.zeros((100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    test[i, i] = 1\n",
    "for j in range(50, 100):\n",
    "    test[50, j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test, origin='lower', interpolation='none')\n",
    "plt.axis('auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filt = filters.gaussian_filter1d(test, 2, axis=0, mode='constant')\n",
    "test_filt = test_filt/np.max(test_filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "plt.imshow(test_filt, origin='lower', interpolation='none')\n",
    "plt.axis('auto')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm /scratch/rmb456/multif0_ismir2017/training_data_with_blur/multif0_complete/CelestialShore_DieForUs_multif0_complete.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
